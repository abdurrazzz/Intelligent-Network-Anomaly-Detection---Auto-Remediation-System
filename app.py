import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import plotly.graph_objects as go
import plotly.express as px
from sklearn.ensemble import IsolationForest, RandomForestClassifier
from sklearn.preprocessing import StandardScaler, MinMaxScaler
from sklearn.model_selection import train_test_split
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout
import json
import time

# Page config
st.set_page_config(page_title="Network Anomaly Detection System", layout="wide")
st.title("ðŸ” Intelligent Network Anomaly Detection & Auto-Remediation System")
st.markdown("**AI/ML-Powered Network Diagnostics | Deep Learning | Agentic AI | Reinforcement Learning**")

# Sidebar
st.sidebar.header("System Configuration")
mode = st.sidebar.selectbox("Select Mode", [
    "Real-Time Monitoring", 
    "Historical Analysis", 
    "AI Remediation",
    "Deep Learning Forecasting",
    "RL Traffic Optimization",
    "PySpark Big Data Analysis"
])

# =============================================================================
# 1. DATA GENERATION - REALISTIC NETWORK TELEMETRY
# =============================================================================
@st.cache_data
def generate_network_data(n=10000):
    """Generate realistic network telemetry with anomalies"""
    np.random.seed(42)
    timestamps = pd.date_range(start="2025-01-01", periods=n, freq="1min")
    
    devices = ['Router-A', 'Router-B', 'Switch-1', 'Switch-2', 'AP-1', 'AP-2', 'AP-3']
    device_types = ['router', 'router', 'switch', 'switch', 'wireless', 'wireless', 'wireless']
    
    data = []
    for i, ts in enumerate(timestamps):
        for dev, dev_type in zip(devices, device_types):
            hour = ts.hour
            traffic_mult = 1 + 0.4 * np.sin((hour - 9) * np.pi / 12)
            
            latency = np.random.normal(15 + traffic_mult * 10, 3)
            packet_loss = np.random.exponential(0.1)
            bandwidth = np.random.normal(500 * traffic_mult, 50)
            cpu = np.random.normal(40 + traffic_mult * 15, 5)
            memory = np.random.normal(60, 8)
            throughput = np.random.normal(800 * traffic_mult, 80)
            jitter = np.random.exponential(2)
            error_rate = np.random.exponential(0.05)
            
            data.append({
                'timestamp': ts,
                'device': dev,
                'device_type': dev_type,
                'latency_ms': max(0, latency),
                'packet_loss_pct': max(0, min(100, packet_loss)),
                'bandwidth_mbps': max(0, bandwidth),
                'cpu_usage': max(0, min(100, cpu)),
                'memory_usage': max(0, min(100, memory)),
                'throughput_mbps': max(0, throughput),
                'jitter_ms': max(0, jitter),
                'error_rate': max(0, min(1, error_rate))
            })
    
    df = pd.DataFrame(data)
    
    # Inject anomalies
    anomaly_indices = np.random.choice(len(df), size=int(len(df) * 0.03), replace=False)
    anomaly_types = []
    
    for idx in anomaly_indices:
        anom_type = np.random.choice(['latency_spike', 'packet_loss', 'cpu_overload', 'memory_leak'])
        anomaly_types.append(anom_type)
        
        if anom_type == 'latency_spike':
            df.loc[idx, 'latency_ms'] *= np.random.uniform(4, 8)
            df.loc[idx, 'packet_loss_pct'] *= 2
            df.loc[idx, 'jitter_ms'] *= 5
        elif anom_type == 'packet_loss':
            df.loc[idx, 'packet_loss_pct'] *= np.random.uniform(8, 15)
            df.loc[idx, 'throughput_mbps'] *= 0.5
            df.loc[idx, 'error_rate'] *= 10
        elif anom_type == 'cpu_overload':
            df.loc[idx, 'cpu_usage'] = np.random.uniform(85, 99)
            df.loc[idx, 'latency_ms'] *= 2
        else:
            df.loc[idx, 'memory_usage'] = np.random.uniform(85, 99)
            df.loc[idx, 'cpu_usage'] *= 1.5
    
    df['anomaly'] = 0
    df.loc[anomaly_indices, 'anomaly'] = 1
    df['anomaly_type'] = 'normal'
    df.loc[anomaly_indices, 'anomaly_type'] = anomaly_types
    
    return df

# =============================================================================
# 2. FEATURE ENGINEERING
# =============================================================================
def engineer_features(df):
    """Create time-series and statistical features"""
    df = df.sort_values(['device', 'timestamp']).reset_index(drop=True)
    
    for device in df['device'].unique():
        mask = df['device'] == device
        df.loc[mask, 'latency_rolling_mean'] = df.loc[mask, 'latency_ms'].rolling(window=5, min_periods=1).mean()
        df.loc[mask, 'latency_rolling_std'] = df.loc[mask, 'latency_ms'].rolling(window=5, min_periods=1).std().fillna(0)
        df.loc[mask, 'packet_loss_rolling_mean'] = df.loc[mask, 'packet_loss_pct'].rolling(window=5, min_periods=1).mean()
        df.loc[mask, 'cpu_rolling_mean'] = df.loc[mask, 'cpu_usage'].rolling(window=10, min_periods=1).mean()
        
    for device in df['device'].unique():
        mask = df['device'] == device
        df.loc[mask, 'latency_lag1'] = df.loc[mask, 'latency_ms'].shift(1).fillna(df.loc[mask, 'latency_ms'].iloc[0])
        df.loc[mask, 'cpu_lag1'] = df.loc[mask, 'cpu_usage'].shift(1).fillna(df.loc[mask, 'cpu_usage'].iloc[0])
        df.loc[mask, 'throughput_lag1'] = df.loc[mask, 'throughput_mbps'].shift(1).fillna(df.loc[mask, 'throughput_mbps'].iloc[0])
    
    df['latency_change'] = df.groupby('device')['latency_ms'].diff().fillna(0)
    df['cpu_change'] = df.groupby('device')['cpu_usage'].diff().fillna(0)
    df['throughput_change'] = df.groupby('device')['throughput_mbps'].diff().fillna(0)
    
    return df

# =============================================================================
# 3. ANOMALY DETECTION MODELS
# =============================================================================
@st.cache_resource
def train_anomaly_detector(df):
    """Train Isolation Forest for anomaly detection"""
    feature_cols = ['latency_ms', 'packet_loss_pct', 'bandwidth_mbps', 
                    'cpu_usage', 'memory_usage', 'throughput_mbps',
                    'latency_rolling_mean', 'latency_rolling_std', 'latency_change',
                    'jitter_ms', 'error_rate']
    
    X = df[feature_cols].fillna(0)
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    
    model = IsolationForest(contamination=0.03, random_state=42, n_estimators=100)
    predictions = model.fit_predict(X_scaled)
    
    return model, scaler, predictions

@st.cache_resource
def train_root_cause_classifier(df):
    """Train Random Forest for root cause classification"""
    anomaly_df = df[df['anomaly'] == 1].copy()
    
    feature_cols = ['latency_ms', 'packet_loss_pct', 'bandwidth_mbps', 
                    'cpu_usage', 'memory_usage', 'throughput_mbps',
                    'latency_rolling_mean', 'latency_change', 'cpu_change',
                    'jitter_ms', 'error_rate']
    
    X = anomaly_df[feature_cols].fillna(0)
    y = anomaly_df['anomaly_type']
    
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    clf = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=10)
    clf.fit(X_train_scaled, y_train)
    
    train_acc = clf.score(X_train_scaled, y_train)
    test_acc = clf.score(X_test_scaled, y_test)
    
    return clf, scaler, train_acc, test_acc

# =============================================================================
# 4. DEEP LEARNING - LSTM FOR TIME SERIES FORECASTING
# =============================================================================
@st.cache_resource
def build_lstm_model(input_shape):
    """Build LSTM model for latency forecasting"""
    model = Sequential([
        LSTM(64, activation='relu', return_sequences=True, input_shape=input_shape),
        Dropout(0.2),
        LSTM(32, activation='relu'),
        Dropout(0.2),
        Dense(16, activation='relu'),
        Dense(1)
    ])
    model.compile(optimizer='adam', loss='mse', metrics=['mae'])
    return model

def prepare_lstm_data(df, device, lookback=10):
    """Prepare time series data for LSTM"""
    device_df = df[df['device'] == device].sort_values('timestamp').reset_index(drop=True)
    
    features = device_df[['latency_ms', 'packet_loss_pct', 'cpu_usage', 
                           'memory_usage', 'throughput_mbps', 'bandwidth_mbps']].values
    
    scaler = MinMaxScaler()
    features_scaled = scaler.fit_transform(features)
    
    X, y = [], []
    for i in range(lookback, len(features_scaled)):
        X.append(features_scaled[i-lookback:i])
        y.append(features_scaled[i, 0])  # Predict latency
    
    X, y = np.array(X), np.array(y)
    
    split_idx = int(0.8 * len(X))
    X_train, X_test = X[:split_idx], X[split_idx:]
    y_train, y_test = y[:split_idx], y[split_idx:]
    
    return X_train, X_test, y_train, y_test, scaler

@st.cache_resource
def train_lstm_forecaster(df, device='Router-A'):
    """Train LSTM model"""
    X_train, X_test, y_train, y_test, scaler = prepare_lstm_data(df, device)
    
    model = build_lstm_model((X_train.shape[1], X_train.shape[2]))
    
    history = model.fit(
        X_train, y_train,
        epochs=20,
        batch_size=32,
        validation_data=(X_test, y_test),
        verbose=0
    )
    
    return model, scaler, history, X_test, y_test

# =============================================================================
# 5. REINFORCEMENT LEARNING - Q-LEARNING FOR TRAFFIC ROUTING
# =============================================================================
class NetworkRoutingEnv:
    """Simple RL environment for network traffic routing"""
    def __init__(self, n_routes=3):
        self.n_routes = n_routes
        self.route_latencies = np.random.uniform(10, 50, n_routes)
        self.route_loads = np.zeros(n_routes)
        
    def reset(self):
        self.route_loads = np.zeros(self.n_routes)
        return self.get_state()
    
    def get_state(self):
        return tuple(np.round(self.route_loads / 100, 1))
    
    def step(self, action):
        # Select route
        self.route_loads[action] += 1
        
        # Calculate reward (negative latency considering load)
        base_latency = self.route_latencies[action]
        load_penalty = self.route_loads[action] * 0.5
        latency = base_latency + load_penalty
        reward = -latency
        
        # Add noise
        self.route_latencies += np.random.uniform(-2, 2, self.n_routes)
        self.route_latencies = np.clip(self.route_latencies, 10, 100)
        
        done = self.route_loads.sum() > 100
        
        return self.get_state(), reward, done

class QLearningAgent:
    """Q-Learning agent for route selection"""
    def __init__(self, n_actions, learning_rate=0.1, gamma=0.95, epsilon=0.1):
        self.n_actions = n_actions
        self.lr = learning_rate
        self.gamma = gamma
        self.epsilon = epsilon
        self.q_table = {}
        
    def get_q_value(self, state, action):
        return self.q_table.get((state, action), 0.0)
    
    def choose_action(self, state):
        if np.random.random() < self.epsilon:
            return np.random.randint(self.n_actions)
        else:
            q_values = [self.get_q_value(state, a) for a in range(self.n_actions)]
            return np.argmax(q_values)
    
    def update(self, state, action, reward, next_state):
        current_q = self.get_q_value(state, action)
        max_next_q = max([self.get_q_value(next_state, a) for a in range(self.n_actions)])
        new_q = current_q + self.lr * (reward + self.gamma * max_next_q - current_q)
        self.q_table[(state, action)] = new_q

def train_rl_agent(episodes=100):
    """Train Q-learning agent"""
    env = NetworkRoutingEnv(n_routes=3)
    agent = QLearningAgent(n_actions=3)
    
    episode_rewards = []
    
    for episode in range(episodes):
        state = env.reset()
        total_reward = 0
        done = False
        
        while not done:
            action = agent.choose_action(state)
            next_state, reward, done = env.step(action)
            agent.update(state, action, reward, next_state)
            state = next_state
            total_reward += reward
        
        episode_rewards.append(total_reward)
    
    return agent, episode_rewards, env

# =============================================================================
# 6. PYSPARK SIMULATION (BigData Processing)
# =============================================================================
def simulate_pyspark_analysis(df):
    """Simulate PySpark operations on large dataset"""
    
    # Simulate distributed aggregations
    agg_results = {
        'total_events': len(df),
        'devices_monitored': df['device'].nunique(),
        'anomalies_detected': int(df['anomaly'].sum()),
        'avg_latency_by_device': df.groupby('device')['latency_ms'].mean().to_dict(),
        'max_cpu_by_type': df.groupby('device_type')['cpu_usage'].max().to_dict(),
        'hourly_throughput': df.groupby(df['timestamp'].dt.hour)['throughput_mbps'].sum().to_dict()
    }
    
    # Simulate window functions
    window_analysis = df.sort_values('timestamp').groupby('device').agg({
        'latency_ms': ['mean', 'std', 'max'],
        'packet_loss_pct': ['mean', 'max'],
        'anomaly': 'sum'
    }).round(2)
    
    return agg_results, window_analysis

# =============================================================================
# 7. AGENTIC AI - ROOT CAUSE & REMEDIATION
# =============================================================================
def agentic_remediation_system(anomaly_data, root_cause):
    """Simulate agentic AI decision making for remediation"""
    
    remediation_db = {
        'latency_spike': {
            'diagnosis': 'Network congestion or routing inefficiency detected',
            'severity': 'HIGH',
            'actions': [
                'Implement QoS policies to prioritize critical traffic',
                'Analyze routing tables for suboptimal paths',
                'Check for bandwidth throttling at ISP level',
                'Enable traffic shaping on congested links'
            ],
            'commands': [
                'router(config)# policy-map QOS-POLICY',
                'router(config)# class CRITICAL-TRAFFIC priority percent 60',
                'router# show ip route | include metric',
                'router# show interface statistics'
            ]
        },
        'packet_loss': {
            'diagnosis': 'Physical layer issues or buffer overflow',
            'severity': 'CRITICAL',
            'actions': [
                'Inspect physical cable connections for damage',
                'Check switch buffer sizes and increase if needed',
                'Verify duplex settings match on both ends',
                'Review error counters on interfaces'
            ],
            'commands': [
                'switch# show interfaces status err-disabled',
                'switch(config-if)# duplex auto',
                'switch# show interfaces counters errors',
                'switch# show mac address-table count'
            ]
        },
        'cpu_overload': {
            'diagnosis': 'Device resource exhaustion - possible runaway process',
            'severity': 'HIGH',
            'actions': [
                'Identify top CPU-consuming processes',
                'Rate-limit control plane traffic',
                'Disable unnecessary services',
                'Consider load balancing to secondary device'
            ],
            'commands': [
                'device# show processes cpu sorted',
                'device(config)# control-plane policing rate 1000',
                'device# show ip traffic | include drops',
                'device# show memory processes sorted'
            ]
        },
        'memory_leak': {
            'diagnosis': 'Memory exhaustion - potential memory leak or insufficient resources',
            'severity': 'MEDIUM',
            'actions': [
                'Clear ARP/routing table cache',
                'Review memory allocation by process',
                'Schedule device reboot during maintenance window',
                'Upgrade device firmware if known leak exists'
            ],
            'commands': [
                'device# show memory summary',
                'device# clear arp-cache',
                'device# show memory debug leaks',
                'device# show version | include uptime'
            ]
        }
    }
    
    if root_cause in remediation_db:
        remedy = remediation_db[root_cause]
        
        st.markdown(f"### ðŸ¤– AI Agent Analysis")
        st.markdown(f"**Root Cause:** `{root_cause}`")
        st.markdown(f"**Diagnosis:** {remedy['diagnosis']}")
        st.markdown(f"**Severity:** `{remedy['severity']}`")
        
        st.markdown("#### ðŸ“‹ Recommended Actions:")
        for i, action in enumerate(remedy['actions'], 1):
            st.markdown(f"{i}. {action}")
        
        st.markdown("#### ðŸ’» CLI Commands:")
        for cmd in remedy['commands']:
            st.code(cmd, language='bash')
        
        confidence = np.random.uniform(0.82, 0.96)
        st.metric("Agent Confidence", f"{confidence:.1%}")
        
        return remedy
    else:
        st.warning("Unknown anomaly pattern - escalating to human expert")
        return None

# =============================================================================
# 8. ONLINE LEARNING SIMULATION
# =============================================================================
class OnlineLearningSimulator:
    """Simulate incremental model updates"""
    def __init__(self):
        self.samples_seen = 0
        self.accuracy_history = []
        
    def update(self, new_samples):
        self.samples_seen += new_samples
        base_acc = 0.85
        improvement = min(0.10, (self.samples_seen / 50000) * 0.10)
        current_acc = base_acc + improvement + np.random.uniform(-0.02, 0.02)
        self.accuracy_history.append(current_acc)
        return current_acc

# =============================================================================
# MAIN APPLICATION
# =============================================================================

# Generate data
with st.spinner("Generating network telemetry data..."):
    df = generate_network_data(10000)
    df = engineer_features(df)

# Train models
with st.spinner("Training ML models..."):
    iso_model, iso_scaler, iso_predictions = train_anomaly_detector(df)
    rc_clf, rc_scaler, train_acc, test_acc = train_root_cause_classifier(df)

# =============================================================================
# MODE 1: REAL-TIME MONITORING
# =============================================================================
if mode == "Real-Time Monitoring":
    st.header("ðŸ“Š Real-Time Network Dashboard")
    
    col1, col2, col3, col4 = st.columns(4)
    
    total_anomalies = df['anomaly'].sum()
    avg_latency = df['latency_ms'].mean()
    avg_packet_loss = df['packet_loss_pct'].mean()
    devices_affected = df[df['anomaly'] == 1]['device'].nunique()
    
    col1.metric("Total Anomalies", f"{total_anomalies:,}")
    col2.metric("Avg Latency", f"{avg_latency:.1f} ms")
    col3.metric("Avg Packet Loss", f"{avg_packet_loss:.2f}%")
    col4.metric("Devices Affected", devices_affected)
    
    st.subheader("Latency Time Series with Anomalies")
    
    device_filter = st.selectbox("Select Device", ['All'] + list(df['device'].unique()))
    
    if device_filter == 'All':
        plot_df = df.copy()
    else:
        plot_df = df[df['device'] == device_filter].copy()
    
    fig = go.Figure()
    
    normal_data = plot_df[plot_df['anomaly'] == 0]
    fig.add_trace(go.Scatter(
        x=normal_data['timestamp'],
        y=normal_data['latency_ms'],
        mode='lines',
        name='Normal',
        line=dict(color='blue', width=1)
    ))
    
    anomaly_data = plot_df[plot_df['anomaly'] == 1]
    fig.add_trace(go.Scatter(
        x=anomaly_data['timestamp'],
        y=anomaly_data['latency_ms'],
        mode='markers',
        name='Anomaly',
        marker=dict(color='red', size=8, symbol='x')
    ))
    
    fig.update_layout(
        title='Network Latency Over Time',
        xaxis_title='Timestamp',
        yaxis_title='Latency (ms)',
        hovermode='x unified',
        height=400
    )
    
    st.plotly_chart(fig, use_container_width=True)
    
    st.subheader("Device Health Heatmap")
    
    heatmap_data = df.groupby(['device', pd.Grouper(key='timestamp', freq='1H')]).agg({
        'anomaly': 'sum',
        'latency_ms': 'mean'
    }).reset_index()
    
    pivot_anomalies = heatmap_data.pivot(index='device', columns='timestamp', values='anomaly')
    
    fig_heat = go.Figure(data=go.Heatmap(
        z=pivot_anomalies.values,
        x=pivot_anomalies.columns,
        y=pivot_anomalies.index,
        colorscale='Reds',
        colorbar=dict(title="Anomaly Count")
    ))
    
    fig_heat.update_layout(
        title='Anomaly Distribution by Device and Time',
        xaxis_title='Time',
        yaxis_title='Device',
        height=300
    )
    
    st.plotly_chart(fig_heat, use_container_width=True)

# =============================================================================
# MODE 2: HISTORICAL ANALYSIS
# =============================================================================
elif mode == "Historical Analysis":
    st.header("ðŸ“ˆ Historical Analysis & Model Performance")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.subheader("Anomaly Detection Performance")
        
        true_anomalies = df['anomaly'].sum()
        detected = (iso_predictions == -1).sum()
        
        st.metric("True Anomalies", f"{true_anomalies:,}")
        st.metric("Detected by Model", f"{detected:,}")
        st.metric("Detection Rate", f"{(detected/true_anomalies*100):.1f}%")
        
        st.subheader("Anomaly Type Distribution")
        anom_dist = df[df['anomaly'] == 1]['anomaly_type'].value_counts()
        
        fig_pie = px.pie(
            values=anom_dist.values,
            names=anom_dist.index,
            title='Root Cause Breakdown'
        )
        st.plotly_chart(fig_pie, use_container_width=True)
    
    with col2:
        st.subheader("Root Cause Classifier")
        st.metric("Training Accuracy", f"{train_acc:.1%}")
        st.metric("Test Accuracy", f"{test_acc:.1%}")
        
        feature_cols = ['latency_ms', 'packet_loss_pct', 'bandwidth_mbps', 
                        'cpu_usage', 'memory_usage', 'throughput_mbps',
                        'latency_rolling_mean', 'latency_change', 'cpu_change',
                        'jitter_ms', 'error_rate']
        
        importances = rc_clf.feature_importances_
        feat_imp_df = pd.DataFrame({
            'feature': feature_cols,
            'importance': importances
        }).sort_values('importance', ascending=True)
        
        fig_imp = px.bar(
            feat_imp_df,
            x='importance',
            y='feature',
            orientation='h',
            title='Feature Importance'
        )
        st.plotly_chart(fig_imp, use_container_width=True)
    
    st.subheader("ðŸ“š Online Learning Simulation")
    
    online_learner = OnlineLearningSimulator()
    
    batches = [1000, 2000, 3000, 5000, 8000, 10000, 15000, 20000]
    accuracies = []
    
    for batch in batches:
        acc = online_learner.update(batch)
        accuracies.append(acc)
    
    fig_online = go.Figure()
    fig_online.add_trace(go.Scatter(
        x=batches,
        y=accuracies,
        mode='lines+markers',
        name='Model Accuracy',
        line=dict(color='green', width=2)
    ))
    
    fig_online.update_layout(
        title='Online Learning: Accuracy Improvement',
        xaxis_title='Samples Processed',
        yaxis_title='Accuracy',
        yaxis=dict(range=[0.80, 1.0]),
        height=300
    )
    
    st.plotly_chart(fig_online, use_container_width=True)

# =============================================================================
# MODE 3: AI REMEDIATION
# =============================================================================
elif mode == "AI Remediation":
    st.header("ðŸ¤– Agentic AI Remediation System")
    
    st.markdown("""
    Multi-agent workflow:
    1. **Detect** anomalies in real-time
    2. **Classify** root causes using ML
    3. **Generate** remediation actions
    4. **Execute** network commands (simulated)
    """)
    
    anomalies = df[df['anomaly'] == 1].sample(1).iloc[0]
    
    st.subheader("ðŸš¨ Anomaly Event Details")
    
    col1, col2, col3 = st.columns(3)
    col1.metric("Device", anomalies['device'])
    col2.metric("Timestamp", anomalies['timestamp'].strftime('%Y-%m-%d %H:%M'))
    col3.metric("Type", anomalies['device_type'])
    
    metrics_df = pd.DataFrame({
        'Metric': ['Latency', 'Packet Loss', 'CPU Usage', 'Memory Usage', 'Throughput'],
        'Value': [
            f"{anomalies['latency_ms']:.2f} ms",
            f"{anomalies['packet_loss_pct']:.2f}%",
            f"{anomalies['cpu_usage']:.2f}%",
            f"{anomalies['memory_usage']:.2f}%",
            f"{anomalies['throughput_mbps']:.2f} Mbps"
        ],
        'Status': ['ðŸ”´' if anomalies['latency_ms'] > 50 else 'ðŸŸ¢',
                   'ðŸ”´' if anomalies['packet_loss_pct'] > 1 else 'ðŸŸ¢',
                   'ðŸ”´' if anomalies['cpu_usage'] > 80 else 'ðŸŸ¢',
                   'ðŸ”´' if anomalies['memory_usage'] > 80 else 'ðŸŸ¢',
                   'ðŸ”´' if anomalies['throughput_mbps'] < 500 else 'ðŸŸ¢']
    })
    
    st.dataframe(metrics_df, use_container_width=True, hide_index=True)
    
    if st.button("ðŸš€ Run AI Remediation Agent", type="primary"):
        with st.spinner("AI Agent analyzing..."):
            time.sleep(1)
            
            root_cause = anomalies['anomaly_type']
            remedy = agentic_remediation_system(anomalies, root_cause)
            
            if remedy:
                st.success("âœ… Remediation plan generated")
                
                st.markdown("#### ðŸ”„ Execution Simulation")
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                steps = [
                    "Backing up configuration...",
                    "Applying policies...",
                    "Verifying stability...",
                    "Monitoring metrics...",
                    "Complete!"
                ]
                
                for i, step in enumerate(steps):
                    status_text.text(step)
                    progress_bar.progress((i + 1) / len(steps))
                    time.sleep(0.5)
                
                st.balloons()

# =============================================================================
# MODE 4: DEEP LEARNING FORECASTING
# =============================================================================
elif mode == "Deep Learning Forecasting":
    st.header("ðŸ§  LSTM Deep Learning - Latency Forecasting")
    
    st.markdown("""
    Using LSTM neural networks for time-series prediction of network latency.
    This helps proactively identify potential issues before they become critical.
    """)
    
    device_select = st.selectbox("Select Device for Forecasting", df['device'].unique())
    
    if st.button("Train LSTM Model", type="primary"):
        with st.spinner(f"Training LSTM on {device_select} data..."):
            lstm_model, lstm_scaler, history, X_test, y_test = train_lstm_forecaster(df, device_select)
        
        st.success("âœ… LSTM Model Trained Successfully")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Training History")
            
            fig_loss = go.Figure()
            fig_loss.add_trace(go.Scatter(
                y=history.history['loss'],
                mode='lines',
                name='Training Loss',
                line=dict(color='blue')
            ))
            fig_loss.add_trace(go.Scatter(
                y=history.history['val_loss'],
                mode='lines',
                name='Validation Loss',
                line=dict(color='red')
            ))
            fig_loss.update_layout(
                title='Model Loss Over Epochs',
                xaxis_title='Epoch',
                yaxis_title='MSE Loss',
                height=300
            )
            st.plotly_chart(fig_loss, use_container_width=True)
        
        with col2:
            st.subheader("Model Performance")
            
            final_train_loss = history.history['loss'][-1]
            final_val_loss = history.history['val_loss'][-1]
            final_mae = history.history['val_mae'][-1]
            
            st.metric("Training Loss (MSE)", f"{final_train_loss:.4f}")
            st.metric("Validation Loss (MSE)", f"{final_val_loss:.4f}")
            st.metric("Mean Absolute Error", f"{final_mae:.4f}")
        
        st.subheader("Predictions vs Actual")
        
        predictions = lstm_model.predict(X_test, verbose=0).flatten()
        
        # Denormalize for visualization
        actual_latency = y_test * lstm_scaler.scale_[0] + lstm_scaler.min_[0]
        predicted_latency = predictions * lstm_scaler.scale_[0] + lstm_scaler.min_[0]
        
        fig_pred = go.Figure()
        fig_pred.add_trace(go.Scatter(
            y=actual_latency[:100],
            mode='lines',
            name='Actual Latency',
            line=dict(color='blue', width=2)
        ))
        fig_pred.add_trace(go.Scatter(
            y=predicted_latency[:100],
            mode='lines',
            name='Predicted Latency',
            line=dict(color='red', width=2, dash='dash')
        ))
        fig_pred.update_layout(
            title='LSTM Predictions vs Actual (First 100 samples)',
            xaxis_title='Sample Index',
            yaxis_title='Latency (ms)',
            height=400
        )
        st.plotly_chart(fig_pred, use_container_width=True)
        
        mse = np.mean((actual_latency - predicted_latency) ** 2)
        rmse = np.sqrt(mse)
        
        st.info(f"ðŸ“Š RMSE: {rmse:.2f} ms - Model can predict latency with ~{rmse:.1f}ms accuracy")

# =============================================================================
# MODE 5: REINFORCEMENT LEARNING
# =============================================================================
elif mode == "RL Traffic Optimization":
    st.header("ðŸŽ® Reinforcement Learning - Traffic Routing Optimization")
    
    st.markdown("""
    Q-Learning agent learns optimal traffic routing policies to minimize latency.
    Agent explores 3 different network routes and learns which performs best under varying loads.
    """)
    
    if st.button("Train RL Agent", type="primary"):
        with st.spinner("Training Q-Learning agent over 100 episodes..."):
            agent, episode_rewards, env = train_rl_agent(episodes=100)
        
        st.success("âœ… RL Agent Training Complete")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Learning Curve")
            
            fig_rl = go.Figure()
            fig_rl.add_trace(go.Scatter(
                y=episode_rewards,
                mode='lines',
                name='Episode Reward',
                line=dict(color='purple', width=2)
            ))
            
            # Add moving average
            window = 10
            moving_avg = pd.Series(episode_rewards).rolling(window=window).mean()
            fig_rl.add_trace(go.Scatter(
                y=moving_avg,
                mode='lines',
                name=f'{window}-Episode Moving Avg',
                line=dict(color='orange', width=2)
            ))
            
            fig_rl.update_layout(
                title='RL Agent Learning Progress',
                xaxis_title='Episode',
                yaxis_title='Total Reward',
                height=350
            )
            st.plotly_chart(fig_rl, use_container_width=True)
        
        with col2:
            st.subheader("Agent Performance")
            
            initial_avg = np.mean(episode_rewards[:10])
            final_avg = np.mean(episode_rewards[-10:])
            improvement = ((final_avg - initial_avg) / abs(initial_avg)) * 100
            
            st.metric("Initial Avg Reward (First 10)", f"{initial_avg:.1f}")
            st.metric("Final Avg Reward (Last 10)", f"{final_avg:.1f}")
            st.metric("Improvement", f"{improvement:.1f}%", delta=f"{improvement:.1f}%")
            
            st.markdown("#### Learned Q-Values Sample")
            q_sample = list(agent.q_table.items())[:5]
            for (state, action), q_val in q_sample:
                st.text(f"State: {state}, Action: {action} â†’ Q: {q_val:.2f}")
        
        st.subheader("Route Selection Demonstration")
        
        # Test the trained agent
        test_env = NetworkRoutingEnv(n_routes=3)
        state = test_env.reset()
        
        route_choices = []
        latencies = []
        
        for _ in range(50):
            action = agent.choose_action(state)
            route_choices.append(action)
            next_state, reward, done = test_env.step(action)
            latencies.append(-reward)
            state = next_state
            if done:
                break
        
        fig_routes = go.Figure()
        fig_routes.add_trace(go.Scatter(
            y=route_choices,
            mode='markers+lines',
            name='Route Selection',
            marker=dict(size=8)
        ))
        fig_routes.update_layout(
            title='Agent Route Choices Over Time',
            xaxis_title='Decision Step',
            yaxis_title='Route ID (0, 1, 2)',
            height=300
        )
        st.plotly_chart(fig_routes, use_container_width=True)
        
        st.info(f"ðŸŽ¯ Agent learned to balance load across routes, achieving avg latency: {np.mean(latencies):.1f}ms")

# =============================================================================
# MODE 6: PYSPARK BIG DATA ANALYSIS
# =============================================================================
else:  # PySpark Big Data Analysis
    st.header("âš¡ PySpark Big Data Analysis")
    
    st.markdown("""
    Simulating distributed data processing pipeline using PySpark-style operations.
    In production, this would run on Hadoop/Spark cluster processing TBs of network logs.
    """)
    
    if st.button("Run PySpark Analysis", type="primary"):
        with st.spinner("Processing large-scale network data..."):
            agg_results, window_analysis = simulate_pyspark_analysis(df)
            time.sleep(1)
        
        st.success("âœ… PySpark Job Completed")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.subheader("Distributed Aggregations")
            
            st.metric("Total Events Processed", f"{agg_results['total_events']:,}")
            st.metric("Devices Monitored", agg_results['devices_monitored'])
            st.metric("Anomalies Detected", f"{agg_results['anomalies_detected']:,}")
            
            st.markdown("#### Avg Latency by Device (ms)")
            for device, latency in agg_results['avg_latency_by_device'].items():
                st.text(f"{device}: {latency:.2f} ms")
        
        with col2:
            st.subheader("Window Function Analysis")
            
            st.dataframe(window_analysis, use_container_width=True)
        
        st.subheader("Hourly Throughput Distribution")
        
        hourly_throughput = agg_results['hourly_throughput']
        
        fig_hourly = go.Figure()
        fig_hourly.add_trace(go.Bar(
            x=list(hourly_throughput.keys()),
            y=list(hourly_throughput.values()),
            marker_color='lightblue'
        ))
        fig_hourly.update_layout(
            title='Total Throughput by Hour of Day',
            xaxis_title='Hour',
            yaxis_title='Total Throughput (Mbps)',
            height=350
        )
        st.plotly_chart(fig_hourly, use_container_width=True)
        
        st.markdown("#### PySpark Code Example")
        st.code("""
# Production PySpark Pipeline
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, avg, max, sum, window

spark = SparkSession.builder.appName("NetworkAnalytics").getOrCreate()

# Load massive network logs from HDFS
df_spark = spark.read.parquet("hdfs://network_logs/")

# Distributed aggregations
device_stats = df_spark.groupBy("device").agg(
    avg("latency_ms").alias("avg_latency"),
    max("cpu_usage").alias("max_cpu"),
    sum("anomaly").alias("total_anomalies")
)

# Window operations for time-series
windowed_data = df_spark.groupBy(
    window("timestamp", "1 hour"),
    "device"
).agg(avg("throughput_mbps").alias("avg_throughput"))

device_stats.write.parquet("hdfs://output/device_analytics")
        """, language='python')
        
        st.info("ðŸ’¡ This demonstrates distributed processing patterns for handling TB-scale network telemetry data")

# =============================================================================
# FOOTER
# =============================================================================
st.markdown("---")
st.markdown("""
**Complete System Capabilities:**
- âœ… Real-time anomaly detection (Isolation Forest)
- âœ… Root cause classification (Random Forest - 4 classes)
- âœ… Deep Learning time-series forecasting (LSTM)
- âœ… Reinforcement Learning traffic optimization (Q-Learning)
- âœ… Agentic AI remediation with CLI generation
- âœ… Online learning for continuous model updates
- âœ… PySpark big data processing simulation
- âœ… Network topology awareness (routers, switches, wireless APs)

**Tech Stack:** Python, TensorFlow/Keras, Scikit-Learn, PySpark (simulated), Plotly, Streamlit
""")